{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Treatment of categorical *features*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2,\n",
    "    stratify=pd.cut(housing[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5]),\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "X_train = train_set.drop(\"median_house_value\", axis=1) # Remove the dependent variable column\n",
    "y_train = train_set[\"median_house_value\"].copy() # Save the dependent variable (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've left aside the 'ocean_proximity' column because it's a categorical variable. Most *Machine Learning* algorithms prefer to work with numbers, so it's better to convert these text categories to numbers. This is called **encoding**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "cat_encoder = OrdinalEncoder()\n",
    "housing_cat_ordinal_encoded = cat_encoder.fit_transform(X_train[[\"ocean_proximity\"]])\n",
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_ordinal_encoded[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OrdinalEncoder` encodes categories as numbers **with an order**. This will make *Machine Learning* algorithms assume that two close values are more similar than two distant values. For example, if we assign to 'NEAR BAY' the value 1, and to 'INLAND' the value 4, the algorithms would assume that 'NEAR BAY' is more similar to 'NEAR OCEAN' (value 2) than to 'INLAND', which is not true.\n",
    "\n",
    "If we know that the categories have an order, we can use an **ordinal** encoding (for example, for ordered categories like \"bad\", \"average\", \"good\" and \"excellent\"). In this case, proximity to the coast seems to have an order. We could do a graphical check by representing the categories on a California map, and see if there's any relationship between the category and proximity to the coast.\n",
    "<!-- TODO: difference with LabelEncoder -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(x=\"longitude\", y=\"latitude\", hue=\"ocean_proximity\", data=X_train)\n",
    "axis = -124.55, -113.95, 32.45, 42.05 # l√≠mites de longitud y latitud de la imagen\n",
    "plt.imshow(PIL.Image.open(\"./img/california.png\", mode='r'), extent=axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there's some relationship between the category and proximity to the coast, it's not clear how the `INLAND` and `NEAR BAY` categories relate to the rest. Therefore, it's better to use a **non-ordinal** encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another common solution when we're not clear about the order of categories is to create a binary attribute per category (convert that column into as many columns as values): an attribute equal to 1 when the category is \"<1H OCEAN\" (and 0 otherwise), another attribute equal to 1 when the category is \"INLAND\" (and 0 otherwise), and so on. This is called ***one-hot encoding***, because only one attribute will be equal to 1 (hot), while the others will be 0 (cold). The new attributes are sometimes called **dummy** attributes. scikit-learn provides the `OneHotEncoder` class to convert categorical values into *one-hot* vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(X_train[[\"ocean_proximity\"]])\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns a ***sparse array*** from **SciPy**, which is a structure that compresses NumPy arrays to save memory when most of its positions contain zeros, storing only non-zero values with their positions. If we want to convert it to a NumPy array, we can use the `toarray()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `sparse_output=False` argument in the `OneHotEncoder` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder(sparse_output=False).fit_transform(X_train[[\"ocean_proximity\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the `get_dummies()` function from pandas does the same thing (but returning a Pandas DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(X_train[\"ocean_proximity\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, OneHotEncoder, being able to separate the training process (with `fit()`) and the transformation process (with `transform()`), remembers the categories it was trained with.\n",
    "\n",
    "This doesn't happen with `get_dummies()`: if used on a test dataset where a category that appeared in the training set doesn't appear, it won't create the corresponding column, and the test and training datasets will have a different number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({\"ocean_proximity\": [\"INLAND\", \"NEAR BAY\"]})\n",
    "pd.get_dummies(df_test) # always maps the existing categories at the time it's called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.transform(df_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how OneHotEncoder maintains the categories it was trained with, even if there are categories without any records.\n",
    "\n",
    "Furthermore, if a category that it hasn't seen before appears in the test set, it will throw an exception. This is useful for detecting problems in the test set, but if we want it to simply ignore unknown categories, we can use the `handle_unknown='ignore'` argument in the `OneHotEncoder` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_unknown = pd.DataFrame({\"ocean_proximity\": [\"<2H OCEAN\", \"ISLAND\"]})\n",
    "pd.get_dummies(df_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_encoder.handle_unknown = \"ignore\" # this way we avoid the exception and simply returns zeros\n",
    "try:\n",
    "    cat_encoder.transform(df_test_unknown).toarray()\n",
    "except Exception as e:\n",
    "    print(\"EXCEPTION:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about how a transformer was trained is stored in its attributes. With the `get_feature_names_out()` method we can obtain the names of the output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.handle_unknown = \"ignore\"\n",
    "df_output = pd.DataFrame(cat_encoder.transform(df_test_unknown).toarray(),\n",
    "                         columns=cat_encoder.get_feature_names_out(),\n",
    "                         index=df_test_unknown.index)\n",
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be taken into consideration that, if a categorical attribute has many categories, the number of columns can grow a lot, which can slow down training and make the model more difficult to train. Additionally, if a category has very few examples, it may not be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wip-clase (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

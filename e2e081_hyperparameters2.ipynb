{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Preprocessing Pipeline\n",
    "\n",
    "The preprocessing pipeline developed in previous notebooks is imported from the shared module [`utils/housing_preprocessing.py`](utils/housing_preprocessing.py). We use a low default value for `n_clusters` since we will be tuning this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from utils.housing_preprocessing import get_preprocessing_pipeline\n",
    "\n",
    "preprocessing = get_preprocessing_pipeline(n_clusters=10)  # Low default, will be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestRegressor(random_state=42, n_jobs=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "The data loading with stratified train/test split is imported from [`utils/load_california.py`](utils/load_california.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_california import load_housing_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the preprocessing pipeline:\n",
    "\n",
    "| Hyperparameter      | Description                                                 |\n",
    "|---------------------|-------------------------------------------------------------|\n",
    "| `n_clusters`        | Number of clusters corresponding to geographic zones.   |\n",
    "| `gamma`             | Rate of decay for similarity with the centroid.        |\n",
    "| `strategy`          | Imputation strategy for missing values (default is mean).        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandomForestRegressor:\n",
    "\n",
    "| Hyperparameter      | Description |\n",
    "|---------------------|-------------|\n",
    "| `n_estimators`     | Number of trees in the forest. More trees can improve accuracy but increase computation time. |\n",
    "| `max_depth`        | Maximum depth of each tree. A low value may lead to *underfitting*, while a high value may lead to *overfitting*. |\n",
    "| `max_features`     | Number of *features* considered at each split. Can be an integer, a percentage, `\"sqrt\"` or `\"log2\"`. Fewer *features* can reduce variance (and thus *overfitting*). |\n",
    "| `min_samples_split` | Minimum number of samples required to split a node. Higher values reduce *overfitting*. |\n",
    "| `min_samples_leaf`  | Minimum number of samples in a leaf. Higher values smooth the prediction. |\n",
    "| `max_samples`      | Percentage of samples used in each tree. Useful for reducing *overfitting*. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Iteration\n",
    "\n",
    "Let's start with a preliminary randomized search using a broad range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/NOCText4/Alejandro/miniconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.6 s, sys: 4.54 s, total: 43.1 s\n",
      "Wall time: 59min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'preprocessing__geo__n_clusters': randint(low=3, high=200),\n",
    "    'random_forest__n_estimators': randint(100, 500),  # Any integer between 100 and 499\n",
    "    'random_forest__max_depth': randint(10, 110),      # Any integer between 10 and 109\n",
    "    'random_forest__min_samples_split': randint(2, 20),\n",
    "    'random_forest__min_samples_leaf': randint(1, 20),\n",
    "    'random_forest__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(\n",
    "    estimator = full_pipeline, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=40, \n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1   # Use all CPU cores in parallel\n",
    "    )\n",
    "\n",
    "_ = rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```%%time``` is a [Jupyter magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-time) that measures the execution time of the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the results of the best models found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>56</td>\n",
       "      <td>225</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>41574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>413</td>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>42508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>145</td>\n",
       "      <td>259</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>43156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>165</td>\n",
       "      <td>330</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>43172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>43476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_clusters  n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "34          56           225         96                  2                 1   \n",
       "3          132           413         73                 13                 1   \n",
       "25         145           259         52                 14                 4   \n",
       "17         165           330         44                 11                 5   \n",
       "21         103           104         56                  2                 3   \n",
       "\n",
       "   max_features  mean_test_score  \n",
       "34         sqrt            41574  \n",
       "3          sqrt            42508  \n",
       "25         sqrt            43156  \n",
       "17         sqrt            43172  \n",
       "21         log2            43476  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(rnd_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "cv_res = cv_res[['param_preprocessing__geo__n_clusters',\n",
    "                 'param_random_forest__n_estimators',\n",
    "                 'param_random_forest__max_depth',\n",
    "                 'param_random_forest__min_samples_split',\n",
    "                 'param_random_forest__min_samples_leaf',\n",
    "                 'param_random_forest__max_features',\n",
    "                 \"mean_test_score\"]]\n",
    "cv_res.columns = [\"n_clusters\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_features\", \"mean_test_score\"]\n",
    "\n",
    "cv_res[\"mean_test_score\"] = -cv_res[\"mean_test_score\"].round().astype(np.int64)\n",
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform successive iterations by fixing *features* where all the best results have converged to a single value, and defining a narrower dictionary of test values centered around the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/NOCText4/Alejandro/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 s, sys: 793 ms, total: 34.8 s\n",
      "Wall time: 10min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "full_pipeline.set_params(random_forest__max_features=\"sqrt\") # Fix the value of max_features, which has converged to \"sqrt\"\n",
    "\n",
    "param_dist = {\n",
    "    'preprocessing__geo__n_clusters': randint(low=55, high=150),\n",
    "    'random_forest__n_estimators': randint(200, 300),\n",
    "    'random_forest__max_depth': randint(44, 97),\n",
    "    'random_forest__min_samples_split': randint(2, 14),\n",
    "    'random_forest__min_samples_leaf': randint(1, 5),\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(\n",
    "    estimator = full_pipeline, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=40, \n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1   # Use all CPU cores in parallel\n",
    "    )\n",
    "\n",
    "_ = rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76</td>\n",
       "      <td>290</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>89</td>\n",
       "      <td>249</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>41678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>116</td>\n",
       "      <td>243</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118</td>\n",
       "      <td>206</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>134</td>\n",
       "      <td>254</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>41848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_clusters  n_estimators  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "6           76           290         87                  2                 1   \n",
       "14          89           249         57                  5                 1   \n",
       "27         116           243         67                  4                 1   \n",
       "9          118           206         46                  4                 1   \n",
       "8          134           254         58                  4                 2   \n",
       "\n",
       "    mean_test_score  \n",
       "6             41604  \n",
       "14            41678  \n",
       "27            41747  \n",
       "9             41846  \n",
       "8             41848  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(rnd_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "cv_res = cv_res[['param_preprocessing__geo__n_clusters',\n",
    "                 'param_random_forest__n_estimators',\n",
    "                 'param_random_forest__max_depth',\n",
    "                 'param_random_forest__min_samples_split',\n",
    "                 'param_random_forest__min_samples_leaf',\n",
    "                 \"mean_test_score\"]]\n",
    "cv_res.columns = [\"n_clusters\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"mean_test_score\"]\n",
    "\n",
    "cv_res[\"mean_test_score\"] = -cv_res[\"mean_test_score\"].round().astype(np.int64)\n",
    "cv_res.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
